{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "contact_rate = 0.5\n",
    "recovery_rate = 0.1\n",
    "total_pop = 1000\n",
    "inf_init = 12\n",
    "n_particles = 100\n",
    "observations = [15, 20, 25, 40, 50]\n",
    "\n",
    "# Updating particles\n",
    "def update_particles(particles, contact_rate, recovery_rate, total_pop):\n",
    "    suscept, infect, recovered = particles[:, 0], particles[:, 1], particles[:, 2]\n",
    "    new_infections = np.random.binomial(suscept.astype(int), 1.0 - np.exp(-contact_rate * infect / total_pop))\n",
    "    new_recoveries = np.random.binomial(infect.astype(int), 1.0 - np.exp(-recovery_rate))\n",
    "    suscept -= new_infections\n",
    "    infect += new_infections - new_recoveries\n",
    "    recovered += new_recoveries\n",
    "    particles = np.vstack([suscept, infect, recovered]).T  # Join the outputs as the columns of the new array\n",
    "    return particles\n",
    "\n",
    "# Calculation of importance weights\n",
    "target_sd = 50.0\n",
    "def get_importance(p_vals, mean):\n",
    "    zero_trunc_vals = -p_vals / target_sd\n",
    "    target = np.array([mean] * n_particles)\n",
    "    return truncnorm.pdf(target, zero_trunc_vals, np.inf, loc=p_vals, scale=target_sd)\n",
    "\n",
    "# Plot results for number of infectious from output array\n",
    "def plot_particle_results(particles):\n",
    "    particles_df = pd.DataFrame(particles[:, 1, :])\n",
    "    df_melted = particles_df.melt(var_name=\"Columns\", value_name=\"Values\")\n",
    "    df_counts = df_melted.groupby([\"Columns\", \"Values\"]).size().reset_index(name=\"Counts\")\n",
    "    results_plot = plt.scatter(df_counts[\"Columns\"], df_counts[\"Values\"], s=df_counts[\"Counts\"] * 15.0, alpha=0.5, label=\"particle results\")\n",
    "    plt.scatter(range(len(observations)), observations, label=\"target\")\n",
    "    plt.legend()\n",
    "    return results_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise particles\n",
    "particles = np.zeros([n_particles, 3, len(observations)])\n",
    "particles[:, 0, 0] = total_pop - inf_init\n",
    "particles[:, 1, 0] = inf_init\n",
    "particles[:, 2, 0] = 0\n",
    "\n",
    "# Main loop\n",
    "for o, obs in enumerate(observations[1:]):\n",
    "    \n",
    "    # Prediction\n",
    "    new_particles = update_particles(particles[:, :, o], contact_rate, recovery_rate, total_pop)\n",
    "\n",
    "    # Importance\n",
    "    weights = get_importance(new_particles[:, 1], obs)\n",
    "    norm_weights = weights / sum(weights)\n",
    "\n",
    "    # Resampling\n",
    "    indices = np.random.choice(range(n_particles), size=n_particles, p=norm_weights)\n",
    "    new_particles = new_particles[indices]\n",
    "    \n",
    "    # Update\n",
    "    particles[:, :, o + 1] = new_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_particle_results(particles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
